{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3331133c",
   "metadata": {},
   "source": [
    "# House Price Prediction Model Development\n",
    "\n",
    "This notebook builds a Random Forest Regressor model to predict house prices using selected features from the House Prices dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde42746",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a17c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2235e8",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a89a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('house_prices_train.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763e99c6",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e541e32",
   "metadata": {},
   "source": [
    "### 3.1 Select Features\n",
    "Selected 6 features from the recommended 9: OverallQual, GrLivArea, TotalBsmtSF, GarageCars, FullBath, YearBuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5499edcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection - 6 features from the recommended 9\n",
    "selected_features = ['OverallQual', 'GrLivArea', 'TotalBsmtSF', 'GarageCars', 'FullBath', 'YearBuilt']\n",
    "target = 'SalePrice'\n",
    "\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "print(f\"Target: {target}\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values before handling:\")\n",
    "print(df[selected_features + [target]].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f00e3e",
   "metadata": {},
   "source": [
    "### 3.2 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a224d3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataset\n",
    "df_processed = df[selected_features + [target]].copy()\n",
    "\n",
    "# Handle missing values - drop rows with any missing values in selected features or target\n",
    "df_processed = df_processed.dropna()\n",
    "\n",
    "print(f\"Dataset shape after removing missing values: {df_processed.shape}\")\n",
    "print(f\"\\nMissing values after handling:\")\n",
    "print(df_processed.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a25a83",
   "metadata": {},
   "source": [
    "### 3.3 Separate Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff57ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_processed[selected_features]\n",
    "y = df_processed[target]\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nTarget statistics:\")\n",
    "print(y.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d6668f",
   "metadata": {},
   "source": [
    "### 3.4 Train/Test Split (BEFORE SCALING - CRITICAL TO AVOID DATA LEAKAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b186dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL: Split BEFORE scaling to avoid data leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Training target shape: {y_train.shape}\")\n",
    "print(f\"Test target shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf5dd7c",
   "metadata": {},
   "source": [
    "### 3.5 Feature Scaling (ONLY on training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f55aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit scaler ONLY on training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Apply the same scaler to test data (transform, NOT fit_transform)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Scaler fitted on training data\")\n",
    "print(f\"X_train_scaled shape: {X_train_scaled.shape}\")\n",
    "print(f\"X_test_scaled shape: {X_test_scaled.shape}\")\n",
    "print(f\"\\nScaler mean (fitted on training): {scaler.mean_}\")\n",
    "print(f\"Scaler scale (fitted on training): {scaler.scale_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ac5bfa",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Random Forest Regressor\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model on scaled training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Model training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be6f04",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af0b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on scaled test data\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate regression metrics\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "train_rmse = np.sqrt(train_mse)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL EVALUATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nTRAINING METRICS:\")\n",
    "print(f\"  MAE:  ${train_mae:,.2f}\")\n",
    "print(f\"  MSE:  ${train_mse:,.2f}\")\n",
    "print(f\"  RMSE: ${train_rmse:,.2f}\")\n",
    "print(f\"  R²:   {train_r2:.4f}\")\n",
    "\n",
    "print(\"\\nTEST METRICS:\")\n",
    "print(f\"  MAE:  ${test_mae:,.2f}\")\n",
    "print(f\"  MSE:  ${test_mse:,.2f}\")\n",
    "print(f\"  RMSE: ${test_rmse:,.2f}\")\n",
    "print(f\"  R²:   {test_r2:.4f}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df860ae",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182f8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': selected_features,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFEATURE IMPORTANCE:\")\n",
    "print(feature_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ddb5a9",
   "metadata": {},
   "source": [
    "## 6. Save Model and Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745a575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model directory if it doesn't exist\n",
    "model_dir = './'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save model using joblib\n",
    "model_path = os.path.join(model_dir, 'house_price_model.pkl')\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = os.path.join(model_dir, 'scaler.pkl')\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"Scaler saved to: {scaler_path}\")\n",
    "\n",
    "# Save selected features list\n",
    "features_path = os.path.join(model_dir, 'selected_features.pkl')\n",
    "joblib.dump(selected_features, features_path)\n",
    "print(f\"Selected features saved to: {features_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ffb20",
   "metadata": {},
   "source": [
    "## 7. Verify Model Reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6941596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the model to ensure it was saved correctly\n",
    "loaded_model = joblib.load(model_path)\n",
    "loaded_scaler = joblib.load(scaler_path)\n",
    "loaded_features = joblib.load(features_path)\n",
    "\n",
    "# Make predictions with reloaded model\n",
    "y_test_pred_reloaded = loaded_model.predict(loaded_scaler.transform(X_test))\n",
    "reloaded_r2 = r2_score(y_test, y_test_pred_reloaded)\n",
    "\n",
    "print(\"Model reloading verification:\")\n",
    "print(f\"  Model reloaded successfully: {loaded_model is not None}\")\n",
    "print(f\"  Scaler reloaded successfully: {loaded_scaler is not None}\")\n",
    "print(f\"  Features reloaded successfully: {loaded_features == selected_features}\")\n",
    "print(f\"  R² score with reloaded model: {reloaded_r2:.4f}\")\n",
    "print(f\"  Matches original R²: {abs(reloaded_r2 - test_r2) < 1e-6}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
